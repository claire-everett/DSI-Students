#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jun 10 21:49:18 2020

@author: miaoyuqi
"""

# process of feature dataset building 

import ssm
import h5py
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import Conspecific_Tracking_ta_edit_117 as cs
from scipy import interpolate 
from hmmlearn import hmm


def data_reading(path):
    # read data for 5 fish
    f = pd.HDFStore(path,'r')
    data_top = f.get('df_with_missing')
    data_top.columns = data_top.columns.droplevel()
#    data_top = cs.auto_scoring_tracefilter(data_top)
#    data_top2 = data_top[data_top.isnull()["F_spine1"]["x"]== False].fillna(method = "ffill")
    return data_top


#### first, filter data with abnormal interval and relative distance
    
def spine_point(data):
    x_index = [0, 15, 18, 21, 24, 27, 30, 33]
    y_index = [1, 16, 19, 22, 25, 28, 31, 34]
    x = data.iloc[:,x_index]
    y = data.iloc[:,y_index]
    spline_point = np.column_stack([x,y])
    spline_point = spline_point.reshape((len(data),8,2), order = "F")

    return spline_point

def Combine_filter_CE (data, p0 = 20  , p1 = 5):
   
    mydata = data.copy()
    #boi = ['A_head','B_rightoperculum','E_leftoperculum',"F_spine1","G_spine2","H_spine3","I_spine4","J_spine5","K_spine6","L_spine7", 'D_tailtip','C_tailbase']
    boi = ['B_rightoperculum','E_leftoperculum',"I_spine4","J_spine5","K_spine6","L_spine7", 'D_tailtip','C_tailbase']
    # for the likelihood with .1 quantile more than 0.5, don't filter by likelihood
    for b in boi:
        for j in ['x','y']:
            xdifference = abs(mydata[b][j].diff())
            xdiff_check = xdifference > p0     
            mydata[b]["x"][xdiff_check] = np.nan
            mydata[b]["y"][xdiff_check] = np.nan
        threshold = mydata[b]['likelihood'].quantile(.1) ## only see the extrem tail?
        print(b +":"+str(threshold))
        lik_check = mydata[b]['likelihood'] < threshold ## likelihood is the larger the better?
        absolute_check = mydata[b]['likelihood'] < 0.8
        mydata[b]['likelihood'][lik_check] = np.nan
        mydata[b]['x'][lik_check] = np.nan
        mydata[b]['y'][lik_check] = np.nan
    return(mydata)

def filter_tailbeating(data,p0=50,p_head = 30, p1=25, p2 = 10, t1 = 20):
    # using likelihood filtered data
    # check points location intervals
    mydata = data.copy()
    spine_column=["A_head","F_spine1","G_spine2","H_spine3","I_spine4","J_spine5","K_spine6","L_spine7"] #,'D_tailtip','C_tailbase']
    for i,c in enumerate(spine_column):
        # using the spine1 as the original points
        if i == 0:
            dist = np.sqrt(np.square(data[spine_column[i+1]]['x']-data[c]['x'])+np.square(data[spine_column[i+1]]['y']-data[c]['y']))
            dist_check = dist > p_head
            mydata[c]["x"][dist_check]  = np.nan
            mydata[c]["y"][dist_check]  = np.nan
        if (i>1 and i<(len(spine_column)-1)):
            r_decision = False
            dist1=np.sqrt(np.square(data[spine_column[i-1]]['x']-data[c]['x'])+np.square(data[spine_column[i-1]]['y']-data[c]['y']))
            dist2=np.sqrt(np.square(data[spine_column[i+1]]['x']-data[c]['x'])+np.square(data[spine_column[i+1]]['y']-data[c]['y']))
            # further check the relative position:
            if i > 2:
                dist3 = np.sqrt(np.square(data["F_spine1"]['x']-data[c]['x'])+np.square(data["F_spine1"]['y']-data[c]['y']))
                if np.logical_or((dist3[0] > ((i-1)*p1+t1)),(dist3[0]<((i-3)*p2))):
                    r_decision = True
            dist_check= np.logical_or(((dist1>p1)|(dist2>p1)), r_decision)
            mydata[c]["x"][dist_check] = np.nan
            mydata[c]["y"][dist_check] = np.nan
        if i==(len(spine_column)-1):
            dist1=np.sqrt(np.square(data[spine_column[i-1]]['x']-data[c]['x'])+np.square(data[spine_column[i-1]]['y']-data[c]['y']))
            dist2=np.sqrt(np.square(data[spine_column[i-2]]['x']-data[c]['x'])+np.square(data[spine_column[i-2]]['y']-data[c]['y']))
            dist3 = np.sqrt(np.square(data["F_spine1"]['x']-data[c]['x'])+np.square(data["F_spine1"]['y']-data[c]['y']))
            r_decision = np.logical_or(dist3[0]>((i-1)*p1), dist3[0]<((i-4)*p2))
            dist_check=np.logical_or(((dist1>p1)|(dist2>p1)), r_decision)
            mydata[c]["x"][dist_check] = np.nan
            mydata[c]["y"][dist_check] = np.nan
        
    return mydata


# visulization
def spine_10plot(data, range_censor):
    j = 0
    fig,ax = plt.subplots(2,5,figsize=(20, 10))
    maintain = list()
    for i in range_censor:
        x = np.array(data[i])
        pts = np.delete(x,np.where(np.isnan(x))[0],axis=0)
        tck, u = interpolate.splprep(pts.T, u=None, s=0.0) 
        u_new = np.linspace(u.min(), u.max(), 1000)
        x_new, y_new = interpolate.splev(u_new, tck, der=0)
        ax[j//5,j%5].plot(pts[:,0], pts[:,1], 'ro')
        ax[j//5,j%5].plot(x_new, y_new, 'b--')
        ax[j//5,j%5].set_title(i)
        maintain.append(len(pts))
        j = j+1
    return maintain



#### then, fill NAs with proper interporlation
# define fill fucntion

def fill_tail(data):
    # data = filter_tail.dropna(subset = (("A_head","x"),('F_spine1','x')))
    data = spine_point(data)
    remain_list = []
    # first find the longest non_na in the point
    for i in range(data.shape[0]):
        not_na = np.unique(np.where(~np.isnan(data[i]))[0])
        if (len(not_na)>=4):
            h = not_na[0]
            s1 = not_na[1]
            if (h == 0) & (s1==1):
                remain_list.append(i) ## filter  when do tail spine
                for j in range(len(not_na)):
                    if j > 1:
                        current = not_na[j]
                        pre = not_na[j-1]
                        point = current-pre
                        if point > 1:
                            dx = data[i][current][0]-data[i][pre][0]
                            dy = data[i][current][1]-data[i][pre][1]
                            for k in range(1, point):
                                data[i][pre+k][0] = data[i][pre][0]+k*dx/point
                                data[i][pre+k][1] = data[i][pre][1]+k*dy/point
    return(data[remain_list],remain_list)
        
# visulization after fill
    
def spine_10plot2(data,remain, range_censor):
    j = 0
    fig,ax = plt.subplots(2,5,figsize=(20, 10))
    maintain = list()
    for i in range_censor:
        x = np.array(data[i])
        pts = np.delete(x,np.where(np.isnan(x))[0],axis=0)
        tck, u = interpolate.splprep(pts.T, u=None, s=0.0) 
        u_new = np.linspace(u.min(), u.max(), 1000)
        x_new, y_new = interpolate.splev(u_new, tck, der=0)
        ax[j//5,j%5].plot(pts[:,0], pts[:,1], 'ro')
        ax[j//5,j%5].plot(x_new, y_new, 'b--')
        ax[j//5,j%5].set_title(remain[i])
        maintain.append(len(pts))
        j = j+1
    return maintain


#### feature: tail_beating
def rotation(data_overall, fill_data):
    data = data_overall
    n = data.shape[0]
    ## transfer spline data to point vector
    spline_point = fill_data

    # origin and reference vector
    head = np.column_stack([data.iloc[:,0],data.iloc[:,1]]) # dim = 216059, 2
    spline1 = np.column_stack([data.iloc[:,15],data.iloc[:,16]])
        # dim = 216059, 2
    head_r = head-spline1

    ##  rotation matrix 
    norm = np.zeros(len(head_r))
    for i in range(len(head_r)):norm[i] =  (np.linalg.norm(head_r[i]))
    #norm = np.array(norm)
    angle = np.column_stack([head_r[:,0]/norm, head_r[:,1]/norm])
    angle2 = np.column_stack([-angle[:,1],angle[:,0]])
    rot_matrix = np.column_stack([angle,angle2])

     ## rotate point coordinates
    spline_rotate = np.zeros((n,8,2))
    for i in range(n):
        x = np.zeros((8,2))
        k = 0
        for j in spline_point[i].reshape((8,2), order = "F"):
            x[k] = np.dot(rot_matrix[i].reshape(2,2),j-spline1[i])
            k = k+1
        spline_rotate[i] = x
    return(spline_rotate)

def tail_spline(rotate_points):
    tail = np.zeros((rotate_points.shape[0],8))
    j=0
    for i in range(len(rotate_points)):
        pts = rotate_points[i]
        pts = np.delete(pts,np.where(np.isnan(pts))[0],axis=0)
        k = pts.shape[0]
        tck, u = interpolate.splprep(pts.T, u=None, s=0.0) 
        yder = interpolate.splev(u, tck, der=1)
        z = np.full(8, np.nan)
        z[0:k] = yder[1]/yder[0]
        tail[i] = np.array(z)
    return(tail)

# for i in range_censor:
#         x = np.array(data[i])
#         pts = np.delete(x,np.where(np.isnan(x))[0],axis=0)
#         tck, u = interpolate.splprep(pts.T, u=None, s=0.0) 
#         u_new = np.linspace(u.min(), u.max(), 1000)
#         x_new, y_new = interpolate.splev(u_new, tck, der=0)



#### feature: oper 
def auto_scoring_get_opdeg(data_auto):
    '''
    Function to automatically score operculum as open or closed based on threshold parameters. 
    
    Parameters: 
    data_auto: traces of behavior collected as a pandas array. 
    thresh_param0: lower threshold for operculum angle
    thresh_param1: upper threshold for operculum angle
    
    Returns:
    pandas array: binary array of open/closed scoring
    '''
    # First collect all parts of interest:
    poi = ['A_head','B_rightoperculum','E_leftoperculum']
    HROP = mydistance(coords(data_auto[poi[0]]),coords(data_auto[poi[1]]))
    HLOP = mydistance(coords(data_auto[poi[0]]),coords(data_auto[poi[2]]))
    RLOP = mydistance(coords(data_auto[poi[1]]),coords(data_auto[poi[2]]))
    
    Operangle = lawofcosines(HROP,HLOP,RLOP)
    
    return Operangle



#### feature: ori
def orientation(data_auto):
    ## take out the head coordinate
    head_x = data_auto["A_head"]["x"]
    head_y = data_auto["A_head"]["y"]
    
    ## get the midpoint coordinate
    mid_x = midpoint(data_auto['B_rightoperculum']['x'], data_auto['B_rightoperculum']['y'], data_auto['E_leftoperculum']['x'], data_auto['E_leftoperculum']['y'])[0]
    mid_y = midpoint(data_auto['B_rightoperculum']['x'], data_auto['B_rightoperculum']['y'], data_auto['E_leftoperculum']['x'], data_auto['E_leftoperculum']['y'])[1]
    
    ## calculate cos theta
    head_ori=np.array([head_x-mid_x,head_y-mid_y]).T
    ref=np.array([1,0])
    inner_product =head_ori.dot(ref)
    cos=inner_product/np.sqrt(np.sum(np.multiply(head_ori,head_ori),axis=1))
    angle=np.arccos(cos)/np.pi*180
    det=head_ori[:,1]>0
    angle[~det]=angle[~det]+180
    angle=np.minimum(angle,360-angle)
    return angle

#### feture: speed
def speed (data, fps = 40):
    
    ''' function that calculates velocity of x/y coordinates
    plug in the xcords, ycords, relevant dataframe, fps
    return the velocity as column in relevant dataframe'''
    poi = ['A_head']
    (Xcoords, Ycoords)= coords(data[poi[0]])
    distx = Xcoords.diff() 
    disty = Ycoords.diff()
    TotalDist = np.sqrt(distx**2 + disty**2)
    Speed = TotalDist / (1/fps) #converts to seconds
#    
    return Speed












